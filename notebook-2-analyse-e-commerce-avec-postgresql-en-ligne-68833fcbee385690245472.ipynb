{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I43NxonzOSDg"
      },
      "source": [
        "# Notebook 2 - SQL avec vraies bases de donn√©es\n",
        "## Analyse e-commerce avec PostgreSQL en ligne\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JItQV6o4Ojrm"
      },
      "source": [
        "\n",
        "### üéØ Objectifs p√©dagogiques\n",
        "- Connecter Python √† une vraie base de donn√©es PostgreSQL\n",
        "- √âcrire des requ√™tes SQL complexes sur des donn√©es r√©elles\n",
        "- Impl√©menter des analyses RFM avec SQL\n",
        "- Int√©grer SQL et pandas pour des analyses avanc√©es\n",
        "- G√©rer les connexions et la s√©curit√©\n",
        "\n",
        "### üõçÔ∏è Contexte du projet\n",
        "Vous analysez les donn√©es d'un vrai dataset e-commerce (Brazilian E-Commerce Public Dataset) h√©berg√© sur une base PostgreSQL.\n",
        "\n",
        "Objectif : cr√©er une segmentation client√®le pour optimiser les campagnes marketing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K79TBMVvOuoj"
      },
      "source": [
        "## Partie 1 : Connexion √† la base de donn√©es r√©elle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq7n18iwPBPe"
      },
      "source": [
        "### üîß Installation et configuration\n",
        "\n",
        "\n",
        "# Installation des d√©pendances\n",
        "\n",
        "\n",
        "```\n",
        "pip install psycopg2-binary sqlalchemy pandas python-dotenv\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "_NuY2FHuOhu3"
      },
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "from sqlalchemy import text\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEbORVz5PXMa"
      },
      "source": [
        "### üåê Base de donn√©es PostgreSQL gratuite (ElephantSQL)\n",
        "\n",
        "**Option 1 : ElephantSQL (20MB gratuit)**\n",
        "1. Cr√©ez un compte sur [elephantsql.com](https://www.elephantsql.com/)\n",
        "2. Cr√©ez une instance \"Tiny Turtle\" (gratuite)\n",
        "3. R√©cup√©rez vos credentials\n",
        "\n",
        "**Option 2 : Supabase (500MB gratuit)**\n",
        "1. Cr√©ez un compte sur [supabase.com](https://supabase.com/)\n",
        "2. Cr√©ez un nouveau projet\n",
        "3. R√©cup√©rez l'URL de connexion PostgreSQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ytLvCF3fQxRJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connexion Ok | Version :  PostgreSQL 17.4 on aarch64-unknown-linux-gnu, compiled by gcc (GCC) 13.2.0, 64-bit\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Configuration de connexion (√† adapter selon votre provider)\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "host = os.getenv('DB_HOST')  #  host Supabase\n",
        "password = os.getenv('DB_PASSWORD')\n",
        "user = os.getenv('DB_USER')\n",
        "database = os.getenv('DB_DATABASE')\n",
        "port = os.getenv('DB_PORT')\n",
        "\n",
        "\n",
        "# Cr√©ation de l'engine SQLAlchemy\n",
        "connection_string = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\"\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Test de connexion\n",
        "def test_connection():\n",
        "    \"\"\"\n",
        "    Testez votre connexion √† la base\n",
        "\n",
        "    √âtapes :\n",
        "    1. Utilisez pd.read_sql() pour ex√©cuter \"SELECT version()\"\n",
        "    2. Affichez la version PostgreSQL\n",
        "    3. G√©rez les erreurs de connexion\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_sql('SELECT version();', engine)\n",
        "        print('Connexion Ok | Version : ', df.iloc[0,0])\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur de connexion : {e}\")\n",
        "        return False\n",
        "    return True\n",
        "test_connection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXfOgAxGQ3b5"
      },
      "source": [
        "\n",
        "## Partie 2 : Import du dataset e-commerce\n",
        "\n",
        "### üìä Dataset Brazilian E-Commerce\n",
        "Nous utilisons le c√©l√®bre dataset Olist (100k commandes r√©elles).\n",
        "\n",
        "**Tables √† cr√©er :**\n",
        "1. **customers** : customer_id, customer_city, customer_state\n",
        "2. **orders** : order_id, customer_id, order_status, order_date, order_delivered_date\n",
        "3. **order_items** : order_id, product_id, seller_id, price, freight_value\n",
        "4. **products** : product_id, product_category, product_weight_g\n",
        "5. **sellers** : seller_id, seller_city, seller_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "olist_order_payments_dataset.csv charg√© : 103886 lignes, 5 colonnes\n",
            "olist_order_reviews_dataset.csv charg√© : 99224 lignes, 7 colonnes\n",
            "olist_products_dataset.csv charg√© : 32951 lignes, 9 colonnes\n",
            "olist_customers_dataset.csv charg√© : 99441 lignes, 5 colonnes\n",
            "olist_sellers_dataset.csv charg√© : 3095 lignes, 4 colonnes\n",
            "olist_orders_dataset.csv charg√© : 99441 lignes, 8 colonnes\n",
            "olist_geolocation_dataset.csv charg√© : 1000163 lignes, 5 colonnes\n",
            "product_category_name_translation.csv charg√© : 71 lignes, 2 colonnes\n",
            "olist_order_items_dataset.csv charg√© : 112650 lignes, 7 colonnes\n"
          ]
        }
      ],
      "source": [
        "# Mise en DataFrame des csv\n",
        "# Liste pour stockers les dataframes\n",
        "df_list = {}\n",
        "# Dossier avec les csv\n",
        "data_folder = \"data\"\n",
        "# Boucle sur les fichiers du dossier \n",
        "for csv in os.listdir(data_folder):\n",
        "    if csv.endswith(\".csv\"): # Filtre les fichiers au format csv\n",
        "        file_path = os.path.join(data_folder, csv)\n",
        "        df = pd.read_csv(file_path) # Lecture des csv\n",
        "        # Stockage dans le dictionnaire df_list\n",
        "        name = os.path.splitext(csv)[0]\n",
        "        df_list[name] = df\n",
        "        print(f'{csv} charg√© : {df.shape[0]} lignes, {df.shape[1]} colonnes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Tables √† cr√©er :**\n",
        "1. **customers** : customer_id, customer_city, customer_state\n",
        "2. **orders** : order_id, customer_id, order_status, order_date, order_delivered_date\n",
        "3. **order_items** : order_id, product_id, seller_id, price, freight_value\n",
        "4. **products** : product_id, product_category, product_weight_g\n",
        "5. **sellers** : seller_id, seller_city, seller_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GqGIXooNSTjp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables supprim√©es.\n",
            "Table Customers cr√©√©e avec succ√®s !\n",
            "Table Commandes cr√©√©e avec succ√®s !\n",
            "Table Vendeurs cr√©√©e avec succ√®s !\n",
            "Table Produits cr√©√©e avec succ√®s !\n",
            "Table Order Items cr√©√©e avec succ√®s !\n"
          ]
        }
      ],
      "source": [
        "### üóÉÔ∏è Cr√©ation des tables SQL\n",
        "\n",
        "def create_tables():\n",
        "\n",
        "    drop_sql = \"\"\"\n",
        "    DROP TABLE IF EXISTS order_items;\n",
        "    DROP TABLE IF EXISTS orders;\n",
        "    DROP TABLE IF EXISTS products;\n",
        "    DROP TABLE IF EXISTS customers;\n",
        "    DROP TABLE IF EXISTS sellers;\n",
        "    DROP TABLE IF EXISTS rm_segments;\n",
        "    \"\"\"\n",
        "    \n",
        "    create_customers = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS customers (\n",
        "        customer_id VARCHAR(50) PRIMARY KEY,\n",
        "        customer_city VARCHAR(100),\n",
        "        customer_state VARCHAR(2)\n",
        "    );\n",
        "    \"\"\"\n",
        "\n",
        "    create_orders = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS orders (\n",
        "        order_id VARCHAR(50) PRIMARY KEY,\n",
        "        customer_id VARCHAR(50),\n",
        "        order_status VARCHAR(20) CHECK (order_status IN (\n",
        "            'created', 'shipped', 'delivered', 'canceled',\n",
        "            'processing', 'invoiced', 'unavailable', 'approved'\n",
        "        )),\n",
        "        order_date TIMESTAMP,\n",
        "        order_delivered_date TIMESTAMP,\n",
        "        CONSTRAINT fk_customer FOREIGN KEY(customer_id) REFERENCES customers(customer_id)\n",
        "    );\n",
        "    \"\"\"\n",
        "\n",
        "    create_products = \"\"\" \n",
        "    CREATE TABLE IF NOT EXISTS products (\n",
        "        product_id VARCHAR(50) PRIMARY KEY,\n",
        "        product_category VARCHAR(50),\n",
        "        product_weight_g NUMERIC CHECK (product_weight_g >= 0)\n",
        "    );\n",
        "    \"\"\"\n",
        "\n",
        "    create_sellers = \"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS sellers (\n",
        "        seller_id VARCHAR(50) PRIMARY KEY,\n",
        "        seller_city VARCHAR(50),\n",
        "        seller_state VARCHAR(2)\n",
        "    );\n",
        "    \"\"\"\n",
        "\n",
        "    create_order_items = \"\"\" \n",
        "    CREATE TABLE IF NOT EXISTS order_items (\n",
        "        order_id VARCHAR(50),\n",
        "        product_id VARCHAR(50),\n",
        "        seller_id VARCHAR(50),\n",
        "        price NUMERIC(10,2) CHECK (price >= 0),\n",
        "        freight_value NUMERIC(10,2) CHECK (freight_value >= 0),\n",
        "        CONSTRAINT fk_orders FOREIGN KEY(order_id) REFERENCES orders(order_id),\n",
        "        CONSTRAINT fk_product FOREIGN KEY(product_id) REFERENCES products(product_id),\n",
        "        CONSTRAINT fk_seller FOREIGN KEY(seller_id) REFERENCES sellers(seller_id)\n",
        "    );\n",
        "    \"\"\"\n",
        "\n",
        "    # Compl√©tez pour les autres tables\n",
        "    # N'oubliez pas les contraintes de cl√©s √©trang√®res !\n",
        "\n",
        "    with engine.connect() as conn:\n",
        "        conn.execute(text(drop_sql))\n",
        "        print('Tables supprim√©es.')\n",
        "        conn.execute(text(create_customers))\n",
        "        print('Table Customers cr√©√©e avec succ√®s !')\n",
        "        conn.execute(text(create_orders))\n",
        "        print('Table Commandes cr√©√©e avec succ√®s !')\n",
        "        conn.execute(text(create_sellers))\n",
        "        print('Table Vendeurs cr√©√©e avec succ√®s !')\n",
        "        conn.execute(text(create_products))\n",
        "        print('Table Produits cr√©√©e avec succ√®s !')\n",
        "        conn.execute(text(create_order_items))\n",
        "        print('Table Order Items cr√©√©e avec succ√®s !')\n",
        "        \n",
        "        # Ex√©cutez les autres CREATE TABLE\n",
        "        conn.commit()\n",
        "create_tables()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traitements des donn√©es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          seller_id        seller_city seller_state\n",
            "0  3442f8959a84dea7ee197c632cb2df15           campinas           SP\n",
            "1  d1b65fc7debc3361ea86b5f14c68d2e2         mogi guacu           SP\n",
            "2  ce3ad9de960102d0677a81f5d0bb7b2d     rio de janeiro           RJ\n",
            "3  c0f3eea2e14555b6faeea3dd58c1b1c3          sao paulo           SP\n",
            "4  51a04a8a6bdcb23deccc82b0b80742cf  braganca paulista           SP\n"
          ]
        }
      ],
      "source": [
        "# Donn√©es vendeurs\n",
        "df_sellers = df_list['olist_sellers_dataset']\n",
        "df_sellers.isna().sum()\n",
        "df_sellers.drop(columns=['seller_zip_code_prefix'], inplace=True)\n",
        "print(df_sellers.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        customer_id          customer_city customer_state\n",
            "0  06b8999e2fba1a1fbc88172c00ba8bc7                 franca             SP\n",
            "1  18955e83d337fd6b2def6b18a428ac77  sao bernardo do campo             SP\n",
            "2  4e7b3e00288586ebd08712fdd0374a03              sao paulo             SP\n",
            "3  b2b6027bc5c5109e529d4dc6358b12c3        mogi das cruzes             SP\n",
            "4  4f2d8ab171c80ec8364f7c12e35b23ad               campinas             SP\n"
          ]
        }
      ],
      "source": [
        "# Donn√©es clients\n",
        "df_customers = df_list['olist_customers_dataset']\n",
        "df_customers.isna().sum()\n",
        "df_customers.drop(columns=['customer_unique_id',\n",
        "                           'customer_zip_code_prefix'],\n",
        "                           inplace=True)\n",
        "print(df_customers.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           order_id                        product_id  \\\n",
            "0  00010242fe8c5a6d1ba2dd792cb16214  4244733e06e7ecb4970a6e2683c13e61   \n",
            "1  00018f77f2f0320c557190d7a144bdd3  e5f2d52b802189ee658865ca93d83a8f   \n",
            "2  000229ec398224ef6ca0657da4fc703e  c777355d18b72b67abbeef9df44fd0fd   \n",
            "3  00024acbcdf0a6daa1e931b038114c75  7634da152a4610f1595efa32f14722fc   \n",
            "4  00042b26cf59d7ce69dfabb4e55b4fd9  ac6c3623068f30de03045865e4e10089   \n",
            "\n",
            "                          seller_id   price  freight_value  \n",
            "0  48436dade18ac8b2bce089ec2a041202   58.90          13.29  \n",
            "1  dd7ddc04e1b6c2c614352b383efe2d36  239.90          19.93  \n",
            "2  5b51032eddd242adc84c38acab88f23d  199.00          17.87  \n",
            "3  9d7a1d34a5052409006425275ba1c2b4   12.99          12.79  \n",
            "4  df560393f3a51e74553ab94004ba5c87  199.90          18.14  \n"
          ]
        }
      ],
      "source": [
        "# Donn√©es objets command√©s\n",
        "\n",
        "df_order_items = df_list['olist_order_items_dataset']\n",
        "df_order_items.isna().sum()\n",
        "df_order_items.drop(columns=['shipping_limit_date'], inplace=True)\n",
        "df_order_items.drop(columns=['order_item_id'], inplace=True)\n",
        "\n",
        "print(df_order_items.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           order_id                       customer_id  \\\n",
            "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
            "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
            "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
            "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
            "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
            "\n",
            "  order_status           order_date order_delivered_date  \n",
            "0    delivered  2017-10-02 10:56:33  2017-10-10 21:25:13  \n",
            "1    delivered  2018-07-24 20:41:37  2018-08-07 15:27:45  \n",
            "2    delivered  2018-08-08 08:38:49  2018-08-17 18:06:29  \n",
            "3    delivered  2017-11-18 19:28:06  2017-12-02 00:28:42  \n",
            "4    delivered  2018-02-13 21:18:39  2018-02-16 18:17:02  \n"
          ]
        }
      ],
      "source": [
        "# Dataframe Commandes\n",
        "df_orders = df_list['olist_orders_dataset']\n",
        "df_orders.isna().sum()\n",
        "\n",
        "# Suppression des colonnes non-utilis√©es\n",
        "df_orders.drop(columns=['order_approved_at', 'order_estimated_delivery_date',\n",
        "                        'order_delivered_carrier_date'], inplace=True)\n",
        "\n",
        "# Renommage de la colonne 'order_purchase_timestamp' en 'order_date'\n",
        "df_orders.rename(columns={'order_purchase_timestamp': 'order_date',\n",
        "                           'order_delivered_customer_date': 'order_delivered_date'},\n",
        "                           inplace=True)\n",
        "# missing_delivery = df_orders[df_orders[\"order_delivered_date\"].isnull()]\\\n",
        "#          .groupby(\"order_status\").size()\n",
        "# print('Commandes sans date de livraison : ', missing_delivery)\n",
        "\n",
        "# # Suppression des donn√©es manquantes dans la colonne 'order_delivered_date' \n",
        "# df_orders = df_orders[df_orders['order_delivered_date'].notnull()]\n",
        "\n",
        "print(df_orders.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             product_id product_category_name  \\\n",
            "105    a41e356c76fab66334f36de622ecbd3a                   NaN   \n",
            "128    d8dee61c2034d6d075997acef1870e9b                   NaN   \n",
            "145    56139431d72cd51f19eb9f7dae4d1617                   NaN   \n",
            "154    46b48281eb6d663ced748f324108c733                   NaN   \n",
            "197    5fb61f482620cb672f5e586bb132eae9                   NaN   \n",
            "...                                 ...                   ...   \n",
            "32515  b0a0c5dd78e644373b199380612c350a                   NaN   \n",
            "32589  10dbe0fbaa2c505123c17fdc34a63c56                   NaN   \n",
            "32616  bd2ada37b58ae94cc838b9c0569fecd8                   NaN   \n",
            "32772  fa51e914046aab32764c41356b9d4ea4                   NaN   \n",
            "32852  c4ceee876c82b8328e9c293fa0e1989b                   NaN   \n",
            "\n",
            "       product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
            "105                    NaN                         NaN                 NaN   \n",
            "128                    NaN                         NaN                 NaN   \n",
            "145                    NaN                         NaN                 NaN   \n",
            "154                    NaN                         NaN                 NaN   \n",
            "197                    NaN                         NaN                 NaN   \n",
            "...                    ...                         ...                 ...   \n",
            "32515                  NaN                         NaN                 NaN   \n",
            "32589                  NaN                         NaN                 NaN   \n",
            "32616                  NaN                         NaN                 NaN   \n",
            "32772                  NaN                         NaN                 NaN   \n",
            "32852                  NaN                         NaN                 NaN   \n",
            "\n",
            "       product_weight_g  product_length_cm  product_height_cm  \\\n",
            "105               650.0               17.0               14.0   \n",
            "128               300.0               16.0                7.0   \n",
            "145               200.0               20.0               20.0   \n",
            "154             18500.0               41.0               30.0   \n",
            "197               300.0               35.0                7.0   \n",
            "...                 ...                ...                ...   \n",
            "32515            1800.0               30.0               20.0   \n",
            "32589             800.0               30.0               10.0   \n",
            "32616             200.0               21.0                8.0   \n",
            "32772            1300.0               45.0               16.0   \n",
            "32852             700.0               28.0                3.0   \n",
            "\n",
            "       product_width_cm  \n",
            "105                12.0  \n",
            "128                20.0  \n",
            "145                20.0  \n",
            "154                41.0  \n",
            "197                12.0  \n",
            "...                 ...  \n",
            "32515              70.0  \n",
            "32589              23.0  \n",
            "32616              16.0  \n",
            "32772              45.0  \n",
            "32852              43.0  \n",
            "\n",
            "[611 rows x 9 columns]\n",
            "                         product_id       product_category  product_weight_g\n",
            "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria             225.0\n",
            "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes            1000.0\n",
            "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer             154.0\n",
            "3  cef67bcfe19066a932b7673e239eb23d                  bebes             371.0\n",
            "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas             625.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_45329/2189663975.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_products['product_category'].fillna(\"uncategorized\", inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Donn√©es produits Produits\n",
        "\n",
        "df_products = df_list['olist_products_dataset']\n",
        "print(df_products[df_products.isnull().any(axis=1)]) # plusieurs donn√©es manquantes\n",
        "df_products.rename(columns={\"product_category_name\": \"product_category\"}, inplace=True) # mise √† jour du nom de colonne en vue d'un export sur la base de donn√©es cr√©e\n",
        "# Gestion des donn√©es manquantes dans la colonne 'product_category'\n",
        "df_products['product_category'].fillna(\"uncategorized\", inplace=True) \n",
        "# df_products.dropna(subset=[\"product_weight_g\"], inplace=True)\n",
        "    # Suppression des colonnes inutiles\n",
        "df_products.drop(columns=[\n",
        "    'product_name_lenght', \n",
        "    'product_description_lenght', \n",
        "    'product_photos_qty', \n",
        "    'product_length_cm', \n",
        "    'product_height_cm', \n",
        "    'product_width_cm'\n",
        "], inplace=True)\n",
        "\n",
        "print(df_products.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export dans la BDD "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Donn√©es ins√©r√©es dans la table customers\n",
            "Donn√©es ins√©r√©es dans la table products\n",
            "Donn√©es ins√©r√©es dans la table orders\n",
            "Donn√©es ins√©r√©es dans la table sellers\n",
            "Donn√©es ins√©r√©es dans la table order_items\n",
            "                           order_id                        product_id  \\\n",
            "0  00010242fe8c5a6d1ba2dd792cb16214  4244733e06e7ecb4970a6e2683c13e61   \n",
            "1  00018f77f2f0320c557190d7a144bdd3  e5f2d52b802189ee658865ca93d83a8f   \n",
            "2  000229ec398224ef6ca0657da4fc703e  c777355d18b72b67abbeef9df44fd0fd   \n",
            "3  00024acbcdf0a6daa1e931b038114c75  7634da152a4610f1595efa32f14722fc   \n",
            "4  00042b26cf59d7ce69dfabb4e55b4fd9  ac6c3623068f30de03045865e4e10089   \n",
            "\n",
            "                          seller_id   price  freight_value  \n",
            "0  48436dade18ac8b2bce089ec2a041202   58.90          13.29  \n",
            "1  dd7ddc04e1b6c2c614352b383efe2d36  239.90          19.93  \n",
            "2  5b51032eddd242adc84c38acab88f23d  199.00          17.87  \n",
            "3  9d7a1d34a5052409006425275ba1c2b4   12.99          12.79  \n",
            "4  df560393f3a51e74553ab94004ba5c87  199.90          18.14  \n"
          ]
        }
      ],
      "source": [
        "# Fonction pour ins√©rer les donner dans la BDD\n",
        "def insert_to_bdd(df, table_name, engine):\n",
        "    try:\n",
        "        df.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
        "        print(f'Donn√©es ins√©r√©es dans la table {table_name}')\n",
        "    except Exception as e:\n",
        "        print(f'Echec de l\\'insertion dans la {table_name} : ', e)\n",
        "\n",
        "# Liste des df associ√©s √† leurs tables\n",
        "datasets = [\n",
        "    (df_customers, 'customers'),\n",
        "    (df_products, 'products'),\n",
        "    (df_orders, 'orders'),\n",
        "    (df_sellers, 'sellers'),\n",
        "    (df_order_items, 'order_items'),\n",
        "]\n",
        "\n",
        "# Insertion\n",
        "for df, table in datasets:\n",
        "    insert_to_bdd(df, table, engine)\n",
        "\n",
        "print(df_order_items.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBQ_BY-QT4dO"
      },
      "source": [
        "## Partie 3 : Requ√™tes SQL avanc√©es\n",
        "\n",
        "\n",
        "### üîç Analyses SQL √† impl√©menter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdl5RNOBUAV2"
      },
      "source": [
        "#### 1. Analyse RFM (R√©cence, Fr√©quence, Montant)\n",
        "```sql\n",
        "-- Votre d√©fi : Calculer les m√©triques RFM pour chaque client\n",
        "WITH customer_metrics AS (\n",
        "    SELECT\n",
        "        c.customer_id,\n",
        "        c.customer_state,\n",
        "        -- R√©cence : jours depuis dernier achat\n",
        "        -- Fr√©quence : nombre de commandes\n",
        "        -- Montant : total d√©pens√©\n",
        "        \n",
        "        -- Compl√©tez cette requ√™te CTE\n",
        "        \n",
        "    FROM customers c\n",
        "    JOIN orders o ON c.customer_id = o.customer_id\n",
        "    JOIN order_items oi ON o.order_id = oi.order_id\n",
        "    WHERE o.order_status = 'delivered'\n",
        "    GROUP BY c.customer_id, c.customer_state\n",
        ")\n",
        "\n",
        "-- Cr√©ez les segments RFM (Champions, Loyaux, √Ä risque, etc.)\n",
        "SELECT\n",
        "    customer_id,\n",
        "    customer_state,\n",
        "    recency_score,\n",
        "    frequency_score,\n",
        "    monetary_score,\n",
        "    CASE\n",
        "        WHEN recency_score >= 4 AND frequency_score >= 4 THEN 'Champions'\n",
        "        WHEN recency_score >= 3 AND frequency_score >= 3 THEN 'Loyal Customers'\n",
        "        -- Ajoutez les autres segments\n",
        "        ELSE 'Others'\n",
        "    END as customer_segment\n",
        "FROM customer_metrics;\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R√©cence\n",
        "- Date de r√©f√©rence\n",
        "- S√©lection des clients en fonction de leur derni√®re date d'achat\n",
        "- Cr√©ation d'un score (1 √† 5)\n",
        "- Attribution du score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2018-10-17 17:30:18\n",
            "                            customer_id  recency_days  r_score\n",
            "0      856336203359aa6a61bf3826f7d84c49           0.0        1\n",
            "1      a4b417188addbc05b26b72d5e44837a1           0.0        1\n",
            "2      4c2ec60c29d10c34bd49cb88aa85cfc4          13.0        1\n",
            "3      bf6181a85bbb4115736c0a8db1a53be3          16.0        1\n",
            "4      2823ffda607a2316375088e0d00005ec          18.0        1\n",
            "...                                 ...           ...      ...\n",
            "99436  b106b360fe2ef8849fbbd056f777b4d5         744.0        5\n",
            "99437  86dc2ffce2dfff336de2f386a786e574         762.0        5\n",
            "99438  622e13439d6b5a0b486c435618b2679e         764.0        5\n",
            "99439  683c54fc24d40ee9f8a6fc179fd9856c         772.0        5\n",
            "99440  08c5351a6aca1c1589a38f244edeee9d         772.0        5\n",
            "\n",
            "[99441 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# RECENCE\n",
        "\n",
        "# Date de r√©f√©rence (plus r√©cente)\n",
        "recence_query_max = \"\"\"\n",
        "SELECT MAX(order_date) AS ref_date FROM orders;\n",
        "\"\"\"\n",
        "df_recence = pd.read_sql_query(recence_query_max, con=engine)\n",
        "\n",
        "ref_date = df_recence['ref_date'].iloc[0] # R√©cup√©ration de la date dans la 1ere ligne\n",
        "print(ref_date)\n",
        "\n",
        "# Requ√™te calcul de r√©cence (l. 17) et attribution du score (l.18)\n",
        "\n",
        "recency_query = text(\"\"\"\n",
        "    SELECT \n",
        "        customer_id,\n",
        "        DATE_PART('day', :ref_date - MAX(order_date)) AS recency_days, \n",
        "        NTILE(5) OVER (ORDER BY DATE_PART('day', :ref_date - MAX(order_date))) AS r_score\n",
        "    FROM orders\n",
        "    GROUP BY customer_id\n",
        "\"\"\")\n",
        "\n",
        "df_rfm_recency = pd.read_sql_query(recency_query, con=engine, params={\"ref_date\": ref_date})\n",
        "\n",
        "print(df_rfm_recency)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fr√©quence\n",
        "- Nombre de commandes par client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "customer_id                       total_orders\n",
            "00012a2ce6f8dcda20d059ce98491703  1               1\n",
            "000161a058600d5901f007fab4c27140  1               1\n",
            "0001fd6190edaaf884bcaf3d49edf079  1               1\n",
            "0002414f95344307404f0ace7a26f1d5  1               1\n",
            "000379cdec625522490c315e70c7a9fb  1               1\n",
            "                                                 ..\n",
            "fffcb937e9dd47a13f05ecb8290f4d3e  1               1\n",
            "fffecc9f79fd8c764f843e9951b11341  1               1\n",
            "fffeda5b6d849fbd39689bb92087f431  1               1\n",
            "ffff42319e9b2d713724ae527742af25  1               1\n",
            "ffffa3172527f765de70084a7e53aae8  1               1\n",
            "Name: count, Length: 98666, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "freq = text(\"\"\"\n",
        "    SELECT o.customer_id, COUNT(DISTINCT o.order_id) AS total_orders\n",
        "    FROM orders o\n",
        "    JOIN order_items oi ON o.order_id = oi.order_id\n",
        "    GROUP BY o.customer_id;\n",
        "\"\"\")\n",
        "\n",
        "total_order = pd.read_sql(freq, con=engine)\n",
        "print(total_order.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Montant\n",
        "- Calcul de montant total des d√©penses par client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        customer_id  total_spent  m_score\n",
            "0  161b6d415e8b3413c6609c70cf405b5a         0.85        1\n",
            "1  9f9d249355f63c5c1216a82b802452c1         0.85        1\n",
            "2  a790343ca6f3fee08112d678b43aa7c5         2.20        1\n",
            "3  184e8e8e48937145eb96c721ef1f0747         2.29        1\n",
            "4  d2c63ad286e3ca9dd69218008d61ff81         2.90        1\n",
            "                            customer_id  total_spent  m_score\n",
            "0      161b6d415e8b3413c6609c70cf405b5a         0.85        1\n",
            "1      9f9d249355f63c5c1216a82b802452c1         0.85        1\n",
            "2      a790343ca6f3fee08112d678b43aa7c5         2.20        1\n",
            "3      184e8e8e48937145eb96c721ef1f0747         2.29        1\n",
            "4      d2c63ad286e3ca9dd69218008d61ff81         2.90        1\n",
            "...                                 ...          ...      ...\n",
            "98661  3fd6777bbce08a352fddd04e4a7cc8f6      6499.00        5\n",
            "98662  f48d464a0baaea338cb25f816991ab1f      6729.00        5\n",
            "98663  c6e2731c5b391845f6800c97401a43a9      6735.00        5\n",
            "98664  ec5b2ba62e574342386871631fafd3fc      7160.00        5\n",
            "98665  1617b1357756262bfa56ab541c47bc16     13440.00        5\n",
            "\n",
            "[98666 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "montant = text(\"\"\"\n",
        "    SELECT customer_id, SUM(oi.price) AS total_spent,\n",
        "    NTILE(5) OVER (ORDER BY SUM(oi.price)) AS m_score\n",
        "    FROM orders o\n",
        "    JOIN order_items oi ON o.order_id = oi.order_id\n",
        "    GROUP BY customer_id\n",
        "    ORDER BY total_spent;\n",
        " \"\"\")\n",
        "\n",
        "total_spent = pd.read_sql_query(montant, con=engine)\n",
        "print(total_spent.head())\n",
        "print(total_spent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyse RM\n",
        "- La fr√©quence n'est pas prise en compte. En effet, selon les donn√©es, chaque client aurait fait une unique commande, ce qui se traduit par une seule cat√©gorie de client pour la fr√©quence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        customer_id  recency_days  r_score  total_spent  \\\n",
            "0  4b7decb9b58e2569548b8b4c8e20e8d7          44.0        1       145.00   \n",
            "1  004440537b68545ca3c341d7279bc4c0          49.0        1        79.98   \n",
            "2  49a6ae8a95c6a78d90945b983ab1ecfc          49.0        1       103.69   \n",
            "3  10a79ef2783cae3d8d678e85fde235ac          49.0        1         6.90   \n",
            "4  930ae890c223dddbd81d9870d9701ec7          49.0        1       169.80   \n",
            "\n",
            "   m_score RM_score  \n",
            "0        4       14  \n",
            "1        3       13  \n",
            "2        3       13  \n",
            "3        1       11  \n",
            "4        4       14  \n"
          ]
        }
      ],
      "source": [
        "# Fusion des scores\n",
        "df_rm = df_rfm_recency.merge(total_spent, on='customer_id')\n",
        "# print(df_rm.head())\n",
        "# Cr√©ation colonne combinant les scores de r√©cence et de montant\n",
        "df_rm[\"RM_score\"] = df_rm['r_score'].astype(str) + df_rm['m_score'].astype(str)\n",
        "print(df_rm.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cr√©ation d'une table pour stocker les r√©sultats d'analyse\n",
        "create_results_table = text(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS rm_segments (\n",
        "        customer_id UUID PRIMARY KEY,\n",
        "        customer_state VARCHAR(50),\n",
        "        recency_score INT,\n",
        "        monetary_score INT,\n",
        "        customer_segment VARCHAR(50)\n",
        "    );\n",
        "\"\"\")\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(create_results_table)\n",
        "    conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insertion des r√©sultats\n",
        "\n",
        "\n",
        "insert_rm_segments = text(\"\"\"\n",
        "    WITH customer_metrics AS (\n",
        "        SELECT\n",
        "            CAST(c.customer_id AS UUID) as customer_id,\n",
        "            c.customer_state,\n",
        "            DATE_PART('day', :ref_date - MAX(o.order_date)) AS recency,\n",
        "            SUM(oi.price) AS monetary\n",
        "        FROM customers c\n",
        "        JOIN orders o ON c.customer_id = o.customer_id\n",
        "        JOIN order_items oi ON o.order_id = oi.order_id\n",
        "        WHERE o.order_status = 'delivered'\n",
        "        GROUP BY c.customer_id, c.customer_state\n",
        "    ),\n",
        "    rm_scored AS (\n",
        "        SELECT \n",
        "            customer_id,\n",
        "            customer_state,\n",
        "            recency,\n",
        "            monetary,\n",
        "            NTILE(5) OVER (ORDER BY recency ASC) AS recency_score,\n",
        "            NTILE(5) OVER (ORDER BY monetary DESC) AS monetary_score\n",
        "        FROM customer_metrics\n",
        "    )\n",
        "    INSERT INTO rm_segments (customer_id, customer_state, recency_score, monetary_score, customer_segment)\n",
        "    SELECT\n",
        "        customer_id,\n",
        "        customer_state,\n",
        "        recency_score,\n",
        "        monetary_score,\n",
        "        CASE\n",
        "            WHEN recency_score >= 4 AND monetary_score >= 4 THEN 'Champions'\n",
        "            WHEN recency_score >= 3 AND monetary_score >= 3 THEN 'Loyal Customers'\n",
        "            WHEN recency_score <= 2 AND monetary_score >= 4 THEN 'At Risk'\n",
        "            WHEN recency_score = 5 AND monetary_score <= 2 THEN 'New & Low Value'\n",
        "            ELSE 'Others'\n",
        "        END AS customer_segment\n",
        "    FROM rm_scored\n",
        "    ON CONFLICT (customer_id) DO UPDATE SET\n",
        "        customer_state = EXCLUDED.customer_state,\n",
        "        recency_score = EXCLUDED.recency_score,\n",
        "        monetary_score = EXCLUDED.monetary_score,\n",
        "        customer_segment = EXCLUDED.customer_segment;\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(insert_rm_segments, {'ref_date': ref_date})\n",
        "    conn.commit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Champions' 'Loyal Customers' 'New & Low Value' 'Others' 'At Risk']\n"
          ]
        }
      ],
      "source": [
        "# Aper√ßu des donn√©es\n",
        "query_rm_segments = text(\"\"\"\n",
        "    SELECT customer_id, customer_state, recency_score, monetary_score, customer_segment\n",
        "    FROM rm_segments\n",
        "    ORDER BY recency_score DESC, monetary_score DESC;\n",
        "\"\"\")\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    df_rm_preview = pd.read_sql_query(query_rm_segments, conn)\n",
        "\n",
        "print(df_rm_preview['customer_segment'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWF9rpZSUMp5"
      },
      "outputs": [],
      "source": [
        "#### 2. Analyse g√©ographique des ventes\n",
        "\n",
        "def geographic_sales_analysis():\n",
        "    \"\"\"\n",
        "    Analysez les performances par √©tat/r√©gion\n",
        "\n",
        "    Requ√™tes √† √©crire :\n",
        "    1. Top 10 des √©tats par CA\n",
        "    2. Croissance MoM par r√©gion\n",
        "    3. Taux de conversion par ville\n",
        "    4. Distance moyenne vendeur-acheteur\n",
        "    \"\"\"\n",
        "\n",
        "    query_top_states = \"\"\"\n",
        "    -- Votre requ√™te SQL ici\n",
        "    -- Utilisez des JOINs et GROUP BY\n",
        "    -- Calculez le CA, nombre de commandes, panier moyen\n",
        "    \"\"\"\n",
        "\n",
        "    return pd.read_sql(query_top_states, engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OE-UHLKY8-K"
      },
      "source": [
        "#### 3. Analyse temporelle et saisonnalit√©\n",
        "```sql\n",
        "-- D√©tectez les patterns saisonniers\n",
        "SELECT\n",
        "    EXTRACT(YEAR FROM order_date) as year,\n",
        "    EXTRACT(MONTH FROM order_date) as month,\n",
        "    EXTRACT(DOW FROM order_date) as day_of_week,\n",
        "    COUNT(*) as order_count,\n",
        "    SUM(price + freight_value) as total_revenue,\n",
        "    AVG(price + freight_value) as avg_order_value\n",
        "FROM orders o\n",
        "JOIN order_items oi ON o.order_id = oi.order_id\n",
        "WHERE order_status = 'delivered'\n",
        "GROUP BY ROLLUP(\n",
        "    EXTRACT(YEAR FROM order_date),\n",
        "    EXTRACT(MONTH FROM order_date),\n",
        "    EXTRACT(DOW FROM order_date)\n",
        ")\n",
        "ORDER BY year, month, day_of_week;\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq43e3mfZC8d"
      },
      "source": [
        "## Partie 4 : Analyse pr√©dictive avec SQL\n",
        "\n",
        "### üîÆ Mod√®les simples en SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY5mfxFoaL2K"
      },
      "outputs": [],
      "source": [
        "#### 1. Pr√©diction de churn\n",
        "\n",
        "def churn_prediction_sql():\n",
        "    \"\"\"\n",
        "    Identifiez les clients √† risque de churn\n",
        "\n",
        "    Indicateurs :\n",
        "    - Pas d'achat depuis X jours\n",
        "    - Baisse de fr√©quence d'achat\n",
        "    - Diminution du panier moyen\n",
        "    - Changement de comportement g√©ographique\n",
        "    \"\"\"\n",
        "\n",
        "    churn_query = \"\"\"\n",
        "    WITH customer_activity AS (\n",
        "        -- Calculez les m√©triques d'activit√© r√©cente\n",
        "        -- Comparez avec l'historique du client\n",
        "        -- Scorez le risque de churn\n",
        "    )\n",
        "\n",
        "    SELECT\n",
        "        customer_id,\n",
        "        days_since_last_order,\n",
        "        order_frequency_trend,\n",
        "        monetary_trend,\n",
        "        churn_risk_score,\n",
        "        CASE\n",
        "            WHEN churn_risk_score > 0.7 THEN 'High Risk'\n",
        "            WHEN churn_risk_score > 0.4 THEN 'Medium Risk'\n",
        "            ELSE 'Low Risk'\n",
        "        END as churn_segment\n",
        "    FROM customer_activity;\n",
        "    \"\"\"\n",
        "\n",
        "    return pd.read_sql(churn_query, engine)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB2D1PDraVu4"
      },
      "source": [
        "#### 2. Recommandations produits\n",
        "```sql\n",
        "-- Market Basket Analysis simplifi√©\n",
        "WITH product_pairs AS (\n",
        "    SELECT\n",
        "        oi1.product_id as product_a,\n",
        "        oi2.product_id as product_b,\n",
        "        COUNT(*) as co_purchase_count\n",
        "    FROM order_items oi1\n",
        "    JOIN order_items oi2 ON oi1.order_id = oi2.order_id\n",
        "    WHERE oi1.product_id != oi2.product_id\n",
        "    GROUP BY oi1.product_id, oi2.product_id\n",
        "    HAVING COUNT(*) >= 10  -- Seuil minimum\n",
        ")\n",
        "\n",
        "SELECT\n",
        "    product_a,\n",
        "    product_b,\n",
        "    co_purchase_count,\n",
        "    co_purchase_count::float / total_a.count as confidence\n",
        "FROM product_pairs pp\n",
        "JOIN (\n",
        "    SELECT product_id, COUNT(*) as count\n",
        "    FROM order_items\n",
        "    GROUP BY product_id\n",
        ") total_a ON pp.product_a = total_a.product_id\n",
        "ORDER BY confidence DESC;\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbYkj8ItabH-"
      },
      "source": [
        "## Partie 5 : Int√©gration avec les APIs m√©t√©o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4CU6SNEfNXb"
      },
      "source": [
        "### üå§Ô∏è Croisement donn√©es m√©t√©o/ventes\n",
        "```python\n",
        "def weather_sales_correlation():\n",
        "    \"\"\"\n",
        "    Correlez vos donn√©es m√©t√©o du Notebook 1 avec les ventes\n",
        "    \n",
        "    Hypoth√®ses √† tester :\n",
        "    1. Les ventes de certaines cat√©gories augmentent-elles avec la pluie ?\n",
        "    2. Y a-t-il un impact de la temp√©rature sur les achats ?\n",
        "    3. Les livraisons sont-elles impact√©es par la m√©t√©o ?\n",
        "    \"\"\"\n",
        "    \n",
        "    # R√©cup√©rez les donn√©es m√©t√©o historiques pour les villes br√©siliennes\n",
        "    weather_query = \"\"\"\n",
        "    SELECT DISTINCT customer_city, customer_state\n",
        "    FROM customers\n",
        "    WHERE customer_state IN ('SP', 'RJ', 'MG', 'RS', 'SC')\n",
        "    ORDER BY customer_city;\n",
        "    \"\"\"\n",
        "    \n",
        "    cities = pd.read_sql(weather_query, engine)\n",
        "    \n",
        "    # Int√©grez avec l'API m√©t√©o\n",
        "    # Analysez les corr√©lations\n",
        "    \n",
        "    pass\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHG9k_5PfZXd"
      },
      "source": [
        "### üìä Dashboard g√©o-temporel\n",
        "```python\n",
        "def create_geotemporal_dashboard():\n",
        "    \"\"\"\n",
        "    Cr√©ez un dashboard interactif combinant :\n",
        "    - Carte des ventes par r√©gion\n",
        "    - √âvolution temporelle avec m√©t√©o\n",
        "    - Segments clients g√©olocalis√©s\n",
        "    - Pr√©dictions par zone g√©ographique\n",
        "    \"\"\"\n",
        "    pass\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsIuD-IVfnxW"
      },
      "source": [
        "---\n",
        "## üèÜ Livrables finaux\n",
        "\n",
        "### üìà Rapport d'analyse complet\n",
        "1. **Segmentation RFM (Recency, Frenquency, Monetary) ** : 5-7 segments avec caract√©ristiques\n",
        "2. **Analyse g√©ographique**  : Performances par r√©gion + recommandations\n",
        "3. **Pr√©dictions churn** : Liste des clients √† risque + actions\n",
        "4. **Recommandations produits** : Top 10 des associations\n",
        "5. **Impact m√©t√©o** : Corr√©lations significatives identifi√©es\n",
        "\n",
        "### üöÄ Pipeline automatis√©\n",
        "```python\n",
        "def automated_analysis_pipeline():\n",
        "    \"\"\"\n",
        "    Pipeline qui :\n",
        "    1. Se connecte √† la DB\n",
        "    2. Ex√©cute toutes les analyses\n",
        "    3. Met √† jour les segments clients\n",
        "    4. G√©n√®re le rapport automatiquement\n",
        "    5. Envoie des alertes si n√©cessaire\n",
        "    \"\"\"\n",
        "    pass\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynvmdtNftwf"
      },
      "source": [
        "## üéì Auto-√©valuation\n",
        "\n",
        "- [ ] **Connexion DB** : PostgreSQL fonctionnelle\n",
        "- [ ] **Requ√™tes complexes** : JOINs, CTEs, fonctions analytiques\n",
        "- [ ] **Gestion des erreurs** : Connexions robustes\n",
        "- [ ] **Performance** : Requ√™tes optimis√©es avec index\n",
        "- [ ] **Int√©gration** : SQL + Python + APIs\n",
        "- [ ] **Insights actionables** : Recommandations business claires\n",
        "\n",
        "### üîó Pr√©paration au Notebook 3\n",
        "Le prochain notebook portera sur NoSQL (MongoDB) avec des donn√©es de r√©seaux sociaux et d'IoT, en temps r√©el.\n",
        "\n",
        "### üí° Bases de donn√©es alternatives\n",
        "- **PlanetScale** : MySQL serverless gratuit\n",
        "- **MongoDB Atlas** : 512MB gratuit\n",
        "- **FaunaDB** : Base multi-mod√®le gratuite\n",
        "- **Hasura Cloud** : GraphQL + PostgreSQL"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
